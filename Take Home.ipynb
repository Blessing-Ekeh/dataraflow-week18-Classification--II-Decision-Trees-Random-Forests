{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059250a4",
   "metadata": {},
   "source": [
    "# Week 18: Classification Algorithms Part 2 - Take Home\n",
    "\n",
    "## Learning Objectives\n",
    "By completing this assignment, you will:\n",
    "- Implement Decision Tree classifiers with entropy criterion\n",
    "- Apply Random Forest classifiers with multiple estimators\n",
    "- Understand and compare tree-based classification algorithms\n",
    "- Tune hyperparameters for optimal model performance\n",
    "- Evaluate models using confusion matrices and accuracy metrics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7575891",
   "metadata": {},
   "source": [
    "# Part 1: Tasks\n",
    "\n",
    "These tasks are designed to test your understanding of the fundamental concepts covered in Week 18."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319686b2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Decision Tree Classification\n",
    "\n",
    "**Objective:** Build a Decision Tree classifier to predict customer purchase behavior.\n",
    "\n",
    "**Dataset:** `Task-Datasets/task1_decision_tree_customer_data.csv`\n",
    "\n",
    "### Instructions:\n",
    "1. Import the necessary libraries (pandas, numpy, sklearn)\n",
    "2. Load the dataset and explore its structure\n",
    "3. Separate features (Age, Salary) and target variable (Purchased)\n",
    "4. Split the data into training (80%) and test (20%) sets\n",
    "5. Build a Decision Tree classifier with criterion='entropy' and random_state=0\n",
    "6. Train the model on the training data\n",
    "7. Make predictions on the test set\n",
    "8. Evaluate using confusion matrix and accuracy score\n",
    "\n",
    "### Expected Deliverables:\n",
    "- Confusion matrix\n",
    "- Accuracy score\n",
    "- Brief interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Decision Tree Classification\n",
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c81097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d9531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af69741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train the Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe7a5ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Random Forest Classification\n",
    "\n",
    "**Objective:** Implement a Random Forest classifier to understand ensemble learning for classification.\n",
    "\n",
    "**Dataset:** `Task-Datasets/task2_random_forest_customer_data.csv`\n",
    "\n",
    "### Instructions:\n",
    "1. Import the necessary libraries\n",
    "2. Load the dataset and understand its structure\n",
    "3. Separate features (Age, Salary) and target variable (Purchased)\n",
    "4. Split the data into training (80%) and test (20%) sets\n",
    "5. Build a Random Forest classifier with:\n",
    "   - n_estimators=10\n",
    "   - criterion='entropy'\n",
    "   - random_state=0\n",
    "6. Train the model and make predictions\n",
    "7. Evaluate using confusion matrix and accuracy score\n",
    "8. Compare conceptually with a single Decision Tree\n",
    "\n",
    "### Expected Deliverables:\n",
    "- Confusion matrix\n",
    "- Accuracy score\n",
    "- Brief explanation of why Random Forest might perform differently than a single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Random Forest Classification\n",
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d132b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb0e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target, split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9fd8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd047a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0030cac2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Assignments\n",
    "\n",
    "These assignments require deeper analysis and application of the concepts learned in Week 18."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c628ed4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Assignment 1: Decision Tree Optimization for Customer Churn Prediction\n",
    "\n",
    "**Objective:** Build and optimize a Decision Tree classifier to predict customer churn based on behavioral data.\n",
    "\n",
    "**Dataset:** `Assignment-Dataset/assignment1_decision_tree_optimization.csv`\n",
    "\n",
    "**Context:** A subscription-based company wants to predict which customers are likely to cancel their subscription (churn) so they can proactively engage with at-risk customers.\n",
    "\n",
    "### Instructions:\n",
    "1. Import necessary libraries\n",
    "2. Load and preprocess the dataset\n",
    "3. Perform exploratory data analysis (EDA) to understand the data\n",
    "4. Separate features (Age, Annual_Income, Spending_Score, Years_as_Customer, Online_Purchase_Frequency) and target (Will_Churn)\n",
    "5. Split the data into training (80%) and test (20%) sets with random_state=42\n",
    "6. Build a Decision Tree classifier with criterion='entropy' and random_state=0\n",
    "7. Experiment with different max_depth values (2, 4, 6, 8, 10, None)\n",
    "8. For each max_depth value, calculate:\n",
    "   - Training accuracy\n",
    "   - Test accuracy\n",
    "9. Plot max_depth vs. accuracy (training and test) to visualize overfitting\n",
    "10. Select the optimal max_depth and justify your choice\n",
    "11. Build the final model with the optimal parameters and evaluate it\n",
    "\n",
    "### Expected Deliverables:\n",
    "- EDA visualizations and summary statistics\n",
    "- Plot showing max_depth vs. accuracy\n",
    "- Justification for optimal max_depth selection\n",
    "- Final model evaluation with confusion matrix and accuracy\n",
    "- Discussion on how max_depth affects overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1: Decision Tree Optimization\n",
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719cb3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d437f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data: separate features/target, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06709958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different max_depth values (2, 4, 6, 8, 10, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779de302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot max_depth vs accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final model with optimal max_depth and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da302221",
   "metadata": {},
   "source": [
    "### Analysis and Conclusions\n",
    "\n",
    "*Write your analysis here:*\n",
    "- What is the optimal max_depth and why?\n",
    "- How does max_depth affect overfitting and underfitting?\n",
    "- What features seem most important for predicting churn?\n",
    "- What business recommendations would you make based on this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7c613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "603cb300",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Assignment 2: Random Forest Hyperparameter Tuning for Fraud Detection\n",
    "\n",
    "**Objective:** Optimize a Random Forest classifier for fraud detection by tuning n_estimators.\n",
    "\n",
    "**Dataset:** `Assignment-Dataset/assignment2_random_forest_optimization.csv`\n",
    "\n",
    "**Context:** A financial services company wants to detect fraudulent transactions. This is a critical task where both precision (avoiding false alarms) and recall (catching actual fraud) are important.\n",
    "\n",
    "### Instructions:\n",
    "1. Import necessary libraries\n",
    "2. Load and preprocess the dataset\n",
    "3. Perform exploratory data analysis including:\n",
    "   - Distribution of each feature\n",
    "   - Class imbalance analysis (note: fraud is rare, ~10%)\n",
    "   - Feature correlations\n",
    "4. Separate features (Amount, Time_of_Day, Day_of_Week, Customer_Age, Account_Age_Days, Previous_Transactions) and target (Is_Fraud)\n",
    "5. Split the data into training (80%) and test (20%) sets with random_state=42\n",
    "6. Test different n_estimators values: [5, 10, 25, 50, 100, 150, 200]\n",
    "7. For each n_estimators value, calculate:\n",
    "   - Training accuracy\n",
    "   - Test accuracy\n",
    "   - Precision and Recall for fraud detection\n",
    "8. Plot n_estimators vs. performance metrics\n",
    "9. Select the optimal n_estimators considering both accuracy and fraud detection\n",
    "10. Build the final model and provide comprehensive evaluation\n",
    "\n",
    "### Expected Deliverables:\n",
    "- Complete EDA with visualizations\n",
    "- Plot showing n_estimators vs. accuracy\n",
    "- Analysis of precision/recall trade-off for fraud detection\n",
    "- Final model evaluation with confusion matrix\n",
    "- Discussion on model performance for imbalanced classes\n",
    "- Recommendations for handling class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932797b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 2: Random Forest Optimization for Fraud Detection\n",
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8991c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class imbalance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4cb596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data: separate features/target, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different n_estimators values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82579a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot n_estimators vs performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5cd684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final model with optimal n_estimators and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb0356",
   "metadata": {},
   "source": [
    "### Analysis and Conclusions\n",
    "\n",
    "*Write your analysis here:*\n",
    "- What is the optimal number of trees (n_estimators) and why?\n",
    "- How does the model perform on the imbalanced dataset?\n",
    "- What is the trade-off between precision and recall for fraud detection?\n",
    "- What strategies could be used to improve fraud detection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2d084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b950b25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Assignment 3: Decision Tree vs. Random Forest Comparison\n",
    "\n",
    "**Objective:** Compare Decision Tree and Random Forest classifiers on the same dataset to understand the benefits of ensemble methods.\n",
    "\n",
    "**Dataset:** `Assignment-Dataset/assignment3_classifier_comparison.csv`\n",
    "\n",
    "**Context:** A healthcare provider wants to predict diabetes risk based on patient health indicators. They want to understand which classifier provides better predictions and why.\n",
    "\n",
    "### Instructions:\n",
    "1. Import necessary libraries\n",
    "2. Load and preprocess the dataset\n",
    "3. Perform comprehensive EDA including:\n",
    "   - Feature distributions\n",
    "   - Class distribution (Diabetes_Risk: 0 = Low Risk, 1 = High Risk)\n",
    "   - Feature correlations\n",
    "   - Analysis by physical activity level\n",
    "4. Separate features (Age, BMI, Blood_Pressure, Glucose_Level, Insulin_Level, Family_History, Physical_Activity) and target (Diabetes_Risk)\n",
    "5. Handle categorical feature (Physical_Activity) - encode appropriately (Low=0, Medium=1, High=2)\n",
    "6. Split the data into training (80%) and test (20%) sets with random_state=42\n",
    "7. Implement and evaluate:\n",
    "   - Decision Tree (criterion='entropy', random_state=0)\n",
    "   - Decision Tree (criterion='entropy', max_depth=5, random_state=0)\n",
    "   - Random Forest (n_estimators=10, criterion='entropy', random_state=0)\n",
    "   - Random Forest (n_estimators=50, criterion='entropy', random_state=0)\n",
    "8. Compare all classifiers using:\n",
    "   - Accuracy\n",
    "   - Confusion matrices\n",
    "   - Classification reports (precision, recall, f1-score)\n",
    "9. Determine the best classifier for diabetes risk prediction\n",
    "\n",
    "### Expected Deliverables:\n",
    "- Comprehensive EDA visualizations\n",
    "- Summary table comparing all classifiers\n",
    "- Individual confusion matrices for each classifier\n",
    "- Discussion on why Random Forest might outperform single Decision Tree\n",
    "- Recommendations for healthcare deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59710617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3: Decision Tree vs. Random Forest Comparison\n",
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a38a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ccefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09485d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution and feature correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a8fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data: encode categorical, separate features/target, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Decision Tree (no max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd338f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Decision Tree (max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Random Forest (n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58995a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Random Forest (n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37263ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51875418",
   "metadata": {},
   "source": [
    "### Analysis and Conclusions\n",
    "\n",
    "*Write your analysis here:*\n",
    "- Which classifier performed best overall?\n",
    "- Why does Random Forest typically outperform a single Decision Tree?\n",
    "- What is the effect of max_depth on Decision Tree performance?\n",
    "- What is the effect of n_estimators on Random Forest performance?\n",
    "- Which classifier would you recommend for healthcare deployment and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7abe69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88902d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "591b9542",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Assessment\n",
    "\n",
    "This assessment evaluates your ability to apply all the tree-based classification techniques learned this week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afbddbb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50a29191",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Assessment: End-to-End Employee Attrition Prediction System\n",
    "\n",
    "**Objective:** Build a complete machine learning pipeline to predict employee attrition using Decision Trees and Random Forest classifiers.\n",
    "\n",
    "**Dataset:** `Assessment-Dataset/employee_attrition_prediction.csv`\n",
    "\n",
    "**Context:** A large technology company is concerned about employee turnover. They want to build a predictive model that can identify employees who are likely to leave the company, so HR can proactively engage with at-risk employees and implement retention strategies.\n",
    "\n",
    "---\n",
    "\n",
    "### Section A: Data Loading and Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb886ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e407a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da4576cc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section B: Exploratory Data Analysis\n",
    "\n",
    "1. Analyze the relationship between each feature and employee attrition\n",
    "2. Create visualizations for:\n",
    "   - Distribution of numerical features by attrition status\n",
    "   - Count plots for categorical features by attrition status\n",
    "   - Correlation heatmap for numerical features\n",
    "3. Analyze attrition by:\n",
    "   - Department\n",
    "   - Job satisfaction level\n",
    "   - Work-life balance\n",
    "   - Overtime status\n",
    "4. Document your findings and insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cfe94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section B: Exploratory Data Analysis\n",
    "# Analyze numerical features by attrition status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50db808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features by attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f54e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze attrition by department and other key factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a32469",
   "metadata": {},
   "source": [
    "**EDA Findings:**\n",
    "\n",
    "*Document your key findings here:*\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6bf294",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section C: Data Preprocessing\n",
    "\n",
    "1. Handle categorical variables:\n",
    "   - Encode Gender (Male=1, Female=0)\n",
    "   - Encode Education_Level (Bachelor=0, Master=1, PhD=2)\n",
    "   - Encode Department using Label Encoding or One-Hot Encoding\n",
    "   - Encode Job_Role using Label Encoding\n",
    "   - Encode Overtime (Yes=1, No=0)\n",
    "2. Create feature matrix (X) and target vector (y)\n",
    "   - Features: All columns except Employee_ID and Left_Company\n",
    "   - Target: Left_Company\n",
    "3. Split data into training (80%) and test (20%) sets with random_state=42\n",
    "4. Note: Feature scaling is optional for tree-based methods (discuss why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section C: Data Preprocessing\n",
    "# Handle categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef7cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix and target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8decef1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section D: Model Building\n",
    "\n",
    "Build and evaluate the following classifiers:\n",
    "\n",
    "**D1. Decision Tree Classifier**\n",
    "- Build a basic Decision Tree with criterion='entropy' and random_state=0\n",
    "- Experiment with max_depth values (3, 5, 7, 10, None)\n",
    "- Find the optimal max_depth\n",
    "- Evaluate the best Decision Tree model\n",
    "\n",
    "**D2. Random Forest Classifier**\n",
    "- Build Random Forest with n_estimators=10, criterion='entropy', random_state=0\n",
    "- Experiment with n_estimators values (10, 50, 100, 150)\n",
    "- Find the optimal n_estimators\n",
    "- Evaluate the best Random Forest model\n",
    "\n",
    "**D3. Feature Importance Analysis**\n",
    "- Extract feature importance from both models\n",
    "- Identify top 5 most important features\n",
    "- Visualize feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30efcfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section D1: Decision Tree Classifier\n",
    "# Test different max_depth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot max_depth vs accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e5e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final Decision Tree model with optimal max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section D2: Random Forest Classifier\n",
    "# Test different n_estimators values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8399d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot n_estimators vs accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feefb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final Random Forest model with optimal n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67b632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section D3: Feature Importance Analysis\n",
    "# Extract and visualize feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b40833a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section E: Model Comparison and Selection\n",
    "\n",
    "1. Create a comprehensive comparison table including:\n",
    "   - Accuracy\n",
    "   - Precision\n",
    "   - Recall\n",
    "   - F1-Score\n",
    "2. Visualize the comparison using bar charts\n",
    "3. Analyze confusion matrices for both models\n",
    "4. Select the best model for the employee attrition prediction task\n",
    "5. Justify your model selection considering:\n",
    "   - Overall performance metrics\n",
    "   - Business requirements (cost of false positives vs. false negatives)\n",
    "   - Model interpretability\n",
    "   - Feature importance insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88846941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section E: Model Comparison\n",
    "# Create comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b87810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison using bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrices for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model selection and justification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a8cea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section F: Conclusions and Recommendations\n",
    "\n",
    "Write a comprehensive report addressing:\n",
    "\n",
    "1. **Summary of Findings:**\n",
    "   - Key features influencing employee attrition\n",
    "   - Performance comparison: Decision Tree vs. Random Forest\n",
    "   - Best performing model and configuration\n",
    "\n",
    "2. **Business Recommendations:**\n",
    "   - What are the top factors driving employee attrition?\n",
    "   - Which employee segments are at highest risk?\n",
    "   - What retention strategies would you recommend?\n",
    "\n",
    "3. **Technical Recommendations:**\n",
    "   - Which model should be deployed and why?\n",
    "   - How does Random Forest compare to Decision Tree for this problem?\n",
    "   - What monitoring should be in place?\n",
    "   - How might tree-based methods compare to other classifiers (e.g., KNN, SVM)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf7316",
   "metadata": {},
   "source": [
    "## Final Report\n",
    "\n",
    "### 1. Summary of Findings\n",
    "\n",
    "*Write your summary here:*\n",
    "\n",
    "\n",
    "### 2. Business Recommendations\n",
    "\n",
    "*Write your business recommendations here:*\n",
    "\n",
    "\n",
    "### 3. Technical Recommendations\n",
    "\n",
    "*Write your technical recommendations here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777fb916",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Provide your publication link below!\n",
    "\n",
    "Link: \n",
    "\n",
    "**Good luck!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c340d3d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
